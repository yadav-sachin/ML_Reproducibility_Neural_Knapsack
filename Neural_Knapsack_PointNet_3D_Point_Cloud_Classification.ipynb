{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural Knapsack Experiment Over PointNet Model 3D Classification on ModelNet40 Dataset.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vah5E0Ng3mq_"
      },
      "source": [
        "# Creating PointNet Model in Tensorflow 2\n",
        "Explain what is Pointnet Model?\n",
        "\n",
        "The Architecture main model is given below:\n",
        "![](https://i.imgur.com/ATtugK4.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aAVFTdz3Ti0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fcb7fb3b-fccc-43ca-e6d6-bcc7fbc887e4"
      },
      "source": [
        "import os                               # Handling Data\n",
        "import glob                             \n",
        "import numpy as np                      # Fast Matrix Processing\n",
        "import tensorflow as tf                 # Tensorflow 2\n",
        "from tensorflow import keras            # Keras\n",
        "from tensorflow.keras import layers     # Layers\n",
        "from matplotlib import pyplot as plt    # Plotting\n",
        "tf.random.set_seed(1234)  \n",
        "tf.__version__              "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.7.0'"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdzm5BaU5DJH"
      },
      "source": [
        "def convolutionalLayersWithBatchNormalisation(modelInternals, filters):\n",
        "    modelInternals = layers.Conv1D(filters, kernel_size=1, padding=\"valid\")(modelInternals)\n",
        "    modelInternals = layers.BatchNormalization(momentum=0.0)(modelInternals)\n",
        "    return layers.Activation(\"relu\")(modelInternals)\n",
        "\n",
        "def denseLayersWithBatchNormalisation(modelInternals, filters):\n",
        "    modelInternals = layers.Dense(filters)(modelInternals)\n",
        "    modelInternals = layers.BatchNormalization(momentum=0.0)(modelInternals)\n",
        "    return layers.Activation(\"relu\")(modelInternals)\n",
        "\n",
        "class OrthogonalRegularizer(keras.regularizers.Regularizer):\n",
        "    \"\"\"\n",
        "        Attaching orthognal regulariser to model\n",
        "    \"\"\"\n",
        "    def __init__(self, num_features, l2reg=0.001):\n",
        "        self.num_features = num_features\n",
        "        self.l2reg = l2reg\n",
        "        self.eye = tf.eye(num_features)\n",
        "\n",
        "    def __call__(self, modelInternals):\n",
        "        modelInternals = tf.reshape(modelInternals, (-1, self.num_features, self.num_features))\n",
        "        xxt = tf.tensordot(modelInternals, modelInternals, axes=(2, 2))\n",
        "        xxt = tf.reshape(xxt, (-1, self.num_features, self.num_features))\n",
        "        return tf.reduce_sum(self.l2reg * tf.square(xxt - self.eye))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_h2v-ZE55FF"
      },
      "source": [
        "#### T-net layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCMCNNQ051EQ"
      },
      "source": [
        "def tnet(inputs, num_features):\n",
        "    # Initalise bias as the indentity matrix\n",
        "    bias = keras.initializers.Constant(np.eye(num_features).flatten())\n",
        "    # regulariser\n",
        "    reg = OrthogonalRegularizer(num_features)\n",
        "    # add conv layers\n",
        "    modelInternals = convolutionalLayersWithBatchNormalisation(inputs, 32)\n",
        "    modelInternals = convolutionalLayersWithBatchNormalisation(modelInternals, 64)\n",
        "    modelInternals = convolutionalLayersWithBatchNormalisation(modelInternals, 512)\n",
        "    # add maxpooling 1D\n",
        "    modelInternals = layers.GlobalMaxPooling1D()(modelInternals)\n",
        "    # add dense layers\n",
        "    modelInternals = denseLayersWithBatchNormalisation(modelInternals, 256)\n",
        "    modelInternals = denseLayersWithBatchNormalisation(modelInternals, 128)\n",
        "    modelInternals = layers.Dense(\n",
        "        num_features * num_features,\n",
        "        kernel_initializer=\"zeros\",\n",
        "        bias_initializer=bias,\n",
        "        activity_regularizer=reg,\n",
        "    )(modelInternals)\n",
        "    feat_T = layers.Reshape((num_features, num_features))(modelInternals)\n",
        "    # Apply affine transformation to input features\n",
        "    return layers.Dot(axes=(2, 1))([inputs, feat_T])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaGA6t6I68HN"
      },
      "source": [
        "def getPointNet3D(NUM_CLASSES,NUM_POINTS):\n",
        "    inputs = keras.Input(shape=(NUM_POINTS, 3))\n",
        "    model = tnet(inputs, 3)\n",
        "    model = convolutionalLayersWithBatchNormalisation(model,32)\n",
        "    model = convolutionalLayersWithBatchNormalisation(model,32)\n",
        "    model = tnet(model,32)\n",
        "    model = convolutionalLayersWithBatchNormalisation(model,32)\n",
        "    model = convolutionalLayersWithBatchNormalisation(model,64)\n",
        "    model = convolutionalLayersWithBatchNormalisation(model,512)\n",
        "    model = layers.GlobalMaxPooling1D()(model)\n",
        "    model = denseLayersWithBatchNormalisation(model,256)\n",
        "    model = layers.Dropout(0.3)(model)\n",
        "    model = denseLayersWithBatchNormalisation(model,128)\n",
        "    model = layers.Dropout(0.3)(model)\n",
        "    outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\")(model)\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"pointnet\")\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wz-5_Vai9LCv"
      },
      "source": [
        "## ModelNet40 Dataset\n",
        "It is a dataset ....\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uj7ceZCY9FhR",
        "outputId": "dd79e0d6-d7c7-414d-8153-2ade549bc99b"
      },
      "source": [
        "!wget https://shapenet.cs.stanford.edu/media/modelnet40_ply_hdf5_2048.zip --no-check-certificate"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-30 20:56:45--  https://shapenet.cs.stanford.edu/media/modelnet40_ply_hdf5_2048.zip\n",
            "Resolving shapenet.cs.stanford.edu (shapenet.cs.stanford.edu)... 171.67.77.19\n",
            "Connecting to shapenet.cs.stanford.edu (shapenet.cs.stanford.edu)|171.67.77.19|:443... connected.\n",
            "WARNING: cannot verify shapenet.cs.stanford.edu's certificate, issued by ‘CN=InCommon RSA Server CA,OU=InCommon,O=Internet2,L=Ann Arbor,ST=MI,C=US’:\n",
            "  Issued certificate has expired.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 435212151 (415M) [application/zip]\n",
            "Saving to: ‘modelnet40_ply_hdf5_2048.zip’\n",
            "\n",
            "modelnet40_ply_hdf5 100%[===================>] 415.05M  11.1MB/s    in 37s     \n",
            "\n",
            "2021-11-30 20:57:23 (11.1 MB/s) - ‘modelnet40_ply_hdf5_2048.zip’ saved [435212151/435212151]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skzEhvKH9kl7",
        "outputId": "16aa361e-a654-4935-c373-a20754c19e56"
      },
      "source": [
        "!unzip /content/modelnet40_ply_hdf5_2048.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/modelnet40_ply_hdf5_2048.zip\n",
            "   creating: modelnet40_ply_hdf5_2048/\n",
            "  inflating: modelnet40_ply_hdf5_2048/ply_data_train_2_id2file.json  \n",
            "  inflating: modelnet40_ply_hdf5_2048/ply_data_train2.h5  \n",
            "  inflating: modelnet40_ply_hdf5_2048/ply_data_train4.h5  \n",
            "  inflating: modelnet40_ply_hdf5_2048/ply_data_train1.h5  \n",
            "  inflating: modelnet40_ply_hdf5_2048/train_files.txt  \n",
            "  inflating: modelnet40_ply_hdf5_2048/ply_data_train_4_id2file.json  \n",
            "  inflating: modelnet40_ply_hdf5_2048/ply_data_test1.h5  \n",
            "  inflating: modelnet40_ply_hdf5_2048/ply_data_test0.h5  \n",
            "  inflating: modelnet40_ply_hdf5_2048/ply_data_test_1_id2file.json  \n",
            "  inflating: modelnet40_ply_hdf5_2048/ply_data_train_1_id2file.json  \n",
            "  inflating: modelnet40_ply_hdf5_2048/ply_data_train_0_id2file.json  \n",
            "  inflating: modelnet40_ply_hdf5_2048/test_files.txt  \n",
            "  inflating: modelnet40_ply_hdf5_2048/ply_data_train0.h5  \n",
            "  inflating: modelnet40_ply_hdf5_2048/ply_data_test_0_id2file.json  \n",
            "  inflating: modelnet40_ply_hdf5_2048/shape_names.txt  \n",
            "  inflating: modelnet40_ply_hdf5_2048/ply_data_train3.h5  \n",
            "  inflating: modelnet40_ply_hdf5_2048/ply_data_train_3_id2file.json  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOx5cdli-cCr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9ad6159-90dd-41fe-aa63-d056a9d60b50"
      },
      "source": [
        "import h5py\n",
        "# colleting train data from 4 hdfs files\n",
        "fp = h5py.File(\"/content/modelnet40_ply_hdf5_2048/ply_data_train0.h5\",'r')  \n",
        "fp1 = h5py.File(\"/content/modelnet40_ply_hdf5_2048/ply_data_train1.h5\",'r')\n",
        "fp2 = h5py.File(\"/content/modelnet40_ply_hdf5_2048/ply_data_train2.h5\",'r')\n",
        "fp3 = h5py.File(\"/content/modelnet40_ply_hdf5_2048/ply_data_train3.h5\",'r')\n",
        "fp4 = h5py.File(\"/content/modelnet40_ply_hdf5_2048/ply_data_train4.h5\",'r')\n",
        "trainX = tf.convert_to_tensor(np.concatenate((np.array(fp[\"data\"]),np.array(fp1[\"data\"]),np.array(fp2[\"data\"]),np.array(fp3[\"data\"]),np.array(fp4[\"data\"]))),dtype=tf.float32)\n",
        "trainy = tf.convert_to_tensor(np.concatenate((np.array(fp[\"label\"]),np.array(fp1[\"label\"]),np.array(fp2[\"label\"]),np.array(fp3[\"label\"]),np.array(fp4[\"label\"]))))\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((trainX,trainy))\n",
        "fp = h5py.File(\"/content/modelnet40_ply_hdf5_2048/ply_data_test0.h5\",'r')  \n",
        "fp1 = h5py.File(\"/content/modelnet40_ply_hdf5_2048/ply_data_test1.h5\",'r')  \n",
        "# print(np.array(fp[\"data\"]).shape)\n",
        "testX = tf.convert_to_tensor(np.concatenate((np.array(fp[\"data\"]),np.array(fp1[\"data\"]))),dtype=tf.float32)\n",
        "testy = tf.convert_to_tensor(np.concatenate((np.array(fp[\"label\"]),np.array(fp1[\"label\"]))))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((testX,testy))\n",
        "print(len(train_dataset))\n",
        "print(len(test_dataset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9840\n",
            "2468\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3GXFWC-_pIk"
      },
      "source": [
        "NUM_POINTS = 2048\n",
        "NUM_CLASSES = 40\n",
        "BATCH_SIZE = 32\n",
        "train_dataset = train_dataset.shuffle(len(train_dataset)).batch(BATCH_SIZE)\n",
        "test_dataset = test_dataset.shuffle(len(test_dataset)).batch(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ET_QXv2i_17s",
        "outputId": "3c815ba5-bb94-4c52-e3d4-0b1489962a96"
      },
      "source": [
        "pointNet = getPointNet3D(NUM_CLASSES,NUM_POINTS)\n",
        "pointNet.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    metrics=[\"sparse_categorical_accuracy\"],\n",
        ")\n",
        "history = pointNet.fit(train_dataset, epochs=30, validation_data=test_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"pointnet\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 2048, 3)]    0           []                               \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)                (None, 2048, 32)     128         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 2048, 32)    128         ['conv1d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 2048, 32)     0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)              (None, 2048, 64)     2112        ['activation[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 2048, 64)    256         ['conv1d_1[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 2048, 64)     0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)              (None, 2048, 512)    33280       ['activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 2048, 512)   2048        ['conv1d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 2048, 512)    0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " global_max_pooling1d (GlobalMa  (None, 512)         0           ['activation_2[0][0]']           \n",
            " xPooling1D)                                                                                      \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 256)          131328      ['global_max_pooling1d[0][0]']   \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 256)         1024        ['dense[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 256)          0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 128)          32896       ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 128)         512         ['dense_1[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 128)          0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 9)            1161        ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " reshape (Reshape)              (None, 3, 3)         0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " dot (Dot)                      (None, 2048, 3)      0           ['input_1[0][0]',                \n",
            "                                                                  'reshape[0][0]']                \n",
            "                                                                                                  \n",
            " conv1d_3 (Conv1D)              (None, 2048, 32)     128         ['dot[0][0]']                    \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 2048, 32)    128         ['conv1d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 2048, 32)     0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv1d_4 (Conv1D)              (None, 2048, 32)     1056        ['activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 2048, 32)    128         ['conv1d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 2048, 32)     0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " conv1d_5 (Conv1D)              (None, 2048, 32)     1056        ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 2048, 32)    128         ['conv1d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 2048, 32)     0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " conv1d_6 (Conv1D)              (None, 2048, 64)     2112        ['activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 2048, 64)    256         ['conv1d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 2048, 64)     0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " conv1d_7 (Conv1D)              (None, 2048, 512)    33280       ['activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 2048, 512)   2048        ['conv1d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 2048, 512)    0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " global_max_pooling1d_1 (Global  (None, 512)         0           ['activation_9[0][0]']           \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 256)          131328      ['global_max_pooling1d_1[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 256)         1024        ['dense_3[0][0]']                \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 256)          0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 128)          32896       ['activation_10[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 128)         512         ['dense_4[0][0]']                \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 128)          0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 1024)         132096      ['activation_11[0][0]']          \n",
            "                                                                                                  \n",
            " reshape_1 (Reshape)            (None, 32, 32)       0           ['dense_5[0][0]']                \n",
            "                                                                                                  \n",
            " dot_1 (Dot)                    (None, 2048, 32)     0           ['activation_6[0][0]',           \n",
            "                                                                  'reshape_1[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_8 (Conv1D)              (None, 2048, 32)     1056        ['dot_1[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 2048, 32)    128         ['conv1d_8[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 2048, 32)     0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_9 (Conv1D)              (None, 2048, 64)     2112        ['activation_12[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 2048, 64)    256         ['conv1d_9[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 2048, 64)     0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_10 (Conv1D)             (None, 2048, 512)    33280       ['activation_13[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 2048, 512)   2048        ['conv1d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 2048, 512)    0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " global_max_pooling1d_2 (Global  (None, 512)         0           ['activation_14[0][0]']          \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 256)          131328      ['global_max_pooling1d_2[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 256)         1024        ['dense_6[0][0]']                \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 256)          0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 256)          0           ['activation_15[0][0]']          \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 128)          32896       ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 128)         512         ['dense_7[0][0]']                \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 128)          0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 128)          0           ['activation_16[0][0]']          \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 40)           5160        ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 752,849\n",
            "Trainable params: 746,769\n",
            "Non-trainable params: 6,080\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/30\n",
            "308/308 [==============================] - 107s 300ms/step - loss: 3.1530 - sparse_categorical_accuracy: 0.5034 - val_loss: 2.9661 - val_sparse_categorical_accuracy: 0.5575\n",
            "Epoch 2/30\n",
            "308/308 [==============================] - 91s 296ms/step - loss: 2.4043 - sparse_categorical_accuracy: 0.6605 - val_loss: 2.4967 - val_sparse_categorical_accuracy: 0.6580\n",
            "Epoch 3/30\n",
            "308/308 [==============================] - 91s 296ms/step - loss: 2.1477 - sparse_categorical_accuracy: 0.7191 - val_loss: 2.4711 - val_sparse_categorical_accuracy: 0.6645\n",
            "Epoch 4/30\n",
            "308/308 [==============================] - 91s 296ms/step - loss: 2.0363 - sparse_categorical_accuracy: 0.7478 - val_loss: 2.3669 - val_sparse_categorical_accuracy: 0.6969\n",
            "Epoch 5/30\n",
            "308/308 [==============================] - 91s 295ms/step - loss: 1.9267 - sparse_categorical_accuracy: 0.7745 - val_loss: 2.2454 - val_sparse_categorical_accuracy: 0.7208\n",
            "Epoch 6/30\n",
            "308/308 [==============================] - 91s 296ms/step - loss: 1.8569 - sparse_categorical_accuracy: 0.7903 - val_loss: 2.1513 - val_sparse_categorical_accuracy: 0.7455\n",
            "Epoch 7/30\n",
            "308/308 [==============================] - 91s 296ms/step - loss: 1.7980 - sparse_categorical_accuracy: 0.8047 - val_loss: 2.1834 - val_sparse_categorical_accuracy: 0.7520\n",
            "Epoch 8/30\n",
            "308/308 [==============================] - 91s 296ms/step - loss: 1.7389 - sparse_categorical_accuracy: 0.8161 - val_loss: 2.1672 - val_sparse_categorical_accuracy: 0.7342\n",
            "Epoch 9/30\n",
            "308/308 [==============================] - 91s 296ms/step - loss: 1.7162 - sparse_categorical_accuracy: 0.8221 - val_loss: 2.2570 - val_sparse_categorical_accuracy: 0.7431\n",
            "Epoch 10/30\n",
            "308/308 [==============================] - 91s 296ms/step - loss: 1.6854 - sparse_categorical_accuracy: 0.8308 - val_loss: 2.0557 - val_sparse_categorical_accuracy: 0.7739\n",
            "Epoch 11/30\n",
            "308/308 [==============================] - 91s 296ms/step - loss: 1.6608 - sparse_categorical_accuracy: 0.8334 - val_loss: 1.9865 - val_sparse_categorical_accuracy: 0.7646\n",
            "Epoch 12/30\n",
            "308/308 [==============================] - 91s 296ms/step - loss: 1.6441 - sparse_categorical_accuracy: 0.8384 - val_loss: 1.9847 - val_sparse_categorical_accuracy: 0.7925\n",
            "Epoch 13/30\n",
            "308/308 [==============================] - 91s 295ms/step - loss: 1.6277 - sparse_categorical_accuracy: 0.8429 - val_loss: 2.0105 - val_sparse_categorical_accuracy: 0.7528\n",
            "Epoch 14/30\n",
            "308/308 [==============================] - 91s 294ms/step - loss: 1.5911 - sparse_categorical_accuracy: 0.8548 - val_loss: 2.2577 - val_sparse_categorical_accuracy: 0.7451\n",
            "Epoch 15/30\n",
            "308/308 [==============================] - 91s 295ms/step - loss: 1.6173 - sparse_categorical_accuracy: 0.8446 - val_loss: 1.7912 - val_sparse_categorical_accuracy: 0.8096\n",
            "Epoch 16/30\n",
            "308/308 [==============================] - 91s 295ms/step - loss: 1.5606 - sparse_categorical_accuracy: 0.8591 - val_loss: 1.9008 - val_sparse_categorical_accuracy: 0.8075\n",
            "Epoch 17/30\n",
            "308/308 [==============================] - 91s 295ms/step - loss: 1.5528 - sparse_categorical_accuracy: 0.8613 - val_loss: 1.9853 - val_sparse_categorical_accuracy: 0.7873\n",
            "Epoch 18/30\n",
            "308/308 [==============================] - 91s 295ms/step - loss: 1.5380 - sparse_categorical_accuracy: 0.8655 - val_loss: 1.8632 - val_sparse_categorical_accuracy: 0.8209\n",
            "Epoch 19/30\n",
            "308/308 [==============================] - 91s 295ms/step - loss: 1.5394 - sparse_categorical_accuracy: 0.8637 - val_loss: 1.9347 - val_sparse_categorical_accuracy: 0.7974\n",
            "Epoch 20/30\n",
            "308/308 [==============================] - 91s 295ms/step - loss: 1.5092 - sparse_categorical_accuracy: 0.8720 - val_loss: 2.0897 - val_sparse_categorical_accuracy: 0.7812\n",
            "Epoch 21/30\n",
            "308/308 [==============================] - 91s 295ms/step - loss: 1.5235 - sparse_categorical_accuracy: 0.8668 - val_loss: 2.0549 - val_sparse_categorical_accuracy: 0.7865\n",
            "Epoch 22/30\n",
            "308/308 [==============================] - 91s 295ms/step - loss: 1.4943 - sparse_categorical_accuracy: 0.8747 - val_loss: 1.9685 - val_sparse_categorical_accuracy: 0.7893\n",
            "Epoch 23/30\n",
            "308/308 [==============================] - 91s 295ms/step - loss: 1.4786 - sparse_categorical_accuracy: 0.8800 - val_loss: 2.1556 - val_sparse_categorical_accuracy: 0.7650\n",
            "Epoch 24/30\n",
            "308/308 [==============================] - 91s 295ms/step - loss: 1.4786 - sparse_categorical_accuracy: 0.8793 - val_loss: 1.8713 - val_sparse_categorical_accuracy: 0.8331\n",
            "Epoch 25/30\n",
            "308/308 [==============================] - 91s 295ms/step - loss: 1.4894 - sparse_categorical_accuracy: 0.8762 - val_loss: 1.7197 - val_sparse_categorical_accuracy: 0.8282\n",
            "Epoch 26/30\n",
            "308/308 [==============================] - 91s 295ms/step - loss: 1.4692 - sparse_categorical_accuracy: 0.8816 - val_loss: 2.2872 - val_sparse_categorical_accuracy: 0.7662\n",
            "Epoch 27/30\n",
            "308/308 [==============================] - 91s 295ms/step - loss: 1.4478 - sparse_categorical_accuracy: 0.8870 - val_loss: 1.9891 - val_sparse_categorical_accuracy: 0.8027\n",
            "Epoch 28/30\n",
            "308/308 [==============================] - 91s 295ms/step - loss: 1.4705 - sparse_categorical_accuracy: 0.8829 - val_loss: 1.8249 - val_sparse_categorical_accuracy: 0.8286\n",
            "Epoch 29/30\n",
            "308/308 [==============================] - 91s 295ms/step - loss: 1.4218 - sparse_categorical_accuracy: 0.8946 - val_loss: 1.9509 - val_sparse_categorical_accuracy: 0.7990\n",
            "Epoch 30/30\n",
            "308/308 [==============================] - 91s 295ms/step - loss: 1.4347 - sparse_categorical_accuracy: 0.8928 - val_loss: 3.5373 - val_sparse_categorical_accuracy: 0.7168\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYSVd8OxAO5b"
      },
      "source": [
        "# Hyperparameters\n",
        "\n",
        "exp_num = 1\n",
        "\n",
        "def get_dataset(file_name = \"/content/modelnet40_ply_hdf5_2048/ply_data_test0.h5\"):\n",
        "  global exp_num\n",
        "  if exp_num == 1:\n",
        "    fp = h5py.File(file_name,'r')  \n",
        "    X = np.array(fp[\"data\"])\n",
        "    y = np.array(fp[\"label\"])\n",
        "    return X,y\n",
        "\n",
        "def get_epsilon():\n",
        "  return 1e-6\n",
        "\n",
        "def get_TauUpdate():\n",
        "  return 1.0, 1\n",
        "\n",
        "def get_lr():\n",
        "  global exp_num\n",
        "  if exp_num == 1:\n",
        "    return 1\n",
        "\n",
        "def get_budget():\n",
        "  global exp_num\n",
        "  if exp_num == 1:\n",
        "    return 0.05\n",
        "\n",
        "def get_epochs():\n",
        "  global exp_num\n",
        "  if exp_num == 1:\n",
        "    return 100 # Change Krna h"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syq5uXrdDl_f",
        "outputId": "8be0141e-cd54-4e3c-b08e-f9e2059f3a60"
      },
      "source": [
        "# Use GPU for training\n",
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "print(\"GPUs Available: \", len(physical_devices))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPUs Available:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGQSe4at1DFx"
      },
      "source": [
        "def accuracy(y,y_hat):\n",
        "  for i in range(len(y)):\n",
        "    if y_[i]==y__[i]:\n",
        "      ans+=1\n",
        "  return ans/len(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzJ9gxinDekt",
        "outputId": "71f47ce4-af18-4a7b-eb73-48c16ca83e73"
      },
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "# Get ModelNet40 Test Dataset\n",
        "P, y = get_dataset()\n",
        "\n",
        "y = tf.keras.utils.to_categorical(y)\n",
        "r, s = 1.004, 1\n",
        "epochs = 100\n",
        "Budget = get_budget()\n",
        "size = int(tf.shape(P)[1])\n",
        "init_value = np.random.randn(size, 1).astype(np.float32)\n",
        "\n",
        "# Creating Our Trainable Parameters\n",
        "T = tf.Variable(trainable = False, initial_value = 1.0)\n",
        "e = tf.Variable(trainable = True, initial_value = init_value)\n",
        "Loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "k = 10\n",
        "tolerance = k\n",
        "best = float(\"inf\")\n",
        "lr = 0.1\n",
        "for epoch in range(1, epochs+1):\n",
        "  # Creating Computational Graph of The Entire Forward Pass\n",
        "  with tf.GradientTape() as tape1, tf.GradientTape() as tape2:\n",
        "    tape1.watch(e)\n",
        "    tape2.watch(e)\n",
        "    X0 = tf.math.sigmoid(tf.math.multiply(T, e))\n",
        "    X1 = tf.grad_pass_through(tf.math.round)(X0)\n",
        "    X = tf.math.multiply(P, X1)\n",
        "    y_hat = pointNet(X)\n",
        "    loss = -Loss(y, y_hat)\n",
        "    cost_overrun = (tf.math.reduce_mean(X1)/size) - Budget\n",
        "  # Gradients\n",
        "  grad_o = tape1.gradient(loss, e)\n",
        "  grad_b = tape2.gradient(cost_overrun, e)\n",
        "  y_ = tf.math.argmax(y,axis=1)\n",
        "  y__ = tf.math.argmax(y_hat,axis=1)\n",
        "  ans = 0\n",
        "  accuracy(y_,y__)\n",
        "  print(\"Epochs: \",epoch,\"Accuracy: \",ans/len(y),\"Loss: \",-loss.numpy().tolist())\n",
        "  # If cost_overrun is less than 0 then set beta to 0\n",
        "  if cost_overrun <= 0:\n",
        "    Beta = 0\n",
        "  else:\n",
        "    # Else calculate the terms to update the beta\n",
        "    ob = tf.reduce_sum(tf.multiply(grad_o, grad_b))\n",
        "    bb = tf.reduce_sum(tf.multiply(grad_b, grad_b))\n",
        "    oo = tf.reduce_sum(tf.multiply(grad_o, grad_o))\n",
        "    t1 = ob / (cost_overrun * bb)\n",
        "    t2 = oo / (cost_overrun * bo)\n",
        "    if bo < 0:\n",
        "        Beta = 0\n",
        "    elif bo > 0 and t1 < t2:\n",
        "        Beta = (t1 + t2) / 2\n",
        "    else:\n",
        "        Beta = t1 + (1e-6)\n",
        "    # Early Stopping\n",
        "    if cost_overrun > 0 and int(loss) < best:\n",
        "      tolerance -= 1\n",
        "    else:\n",
        "      best = int(loss)\n",
        "      tolerance = k\n",
        "    if tolerance <= 0:\n",
        "      break\n",
        "\n",
        "  delL = grad_o - Beta*cost_overrun*grad_b + get_epsilon()\n",
        "  e = e + tf.math.scalar_mul(lr, delL) # only update a portion\n",
        "  T = tf.math.scalar_mul(pow(r, epoch//s), T)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs:  1 Accuracy:  0.759493670886076 Loss:  1.0003095865249634\n",
            "Epochs:  2 Accuracy:  0.7848101265822784 Loss:  0.9718227982521057\n",
            "Epochs:  3 Accuracy:  0.7974683544303798 Loss:  0.9564444422721863\n",
            "Epochs:  4 Accuracy:  0.7974683544303798 Loss:  0.928037703037262\n",
            "Epochs:  5 Accuracy:  0.7974683544303798 Loss:  0.8966020941734314\n",
            "Epochs:  6 Accuracy:  0.7974683544303798 Loss:  0.8868858218193054\n",
            "Epochs:  7 Accuracy:  0.7974683544303798 Loss:  0.8731716275215149\n",
            "Epochs:  8 Accuracy:  0.7974683544303798 Loss:  0.861458957195282\n",
            "Epochs:  9 Accuracy:  0.810126582278481 Loss:  0.8698155879974365\n",
            "Epochs:  10 Accuracy:  0.810126582278481 Loss:  0.8560367822647095\n",
            "Epochs:  11 Accuracy:  0.8227848101265823 Loss:  0.8224151134490967\n",
            "Early Stopping...\n",
            "Breaked\n",
            "Epochs:  11 Accuracy:  0.8227848101265823 Loss:  0.8224151134490967\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JLCvxDOqajd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}